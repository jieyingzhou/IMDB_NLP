{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/imdb-review-dataset/imdb_master.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10001_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10002_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10003_3.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type                                             review label  \\\n",
       "0           0  test  Once again Mr. Costner has dragged out a movie...   neg   \n",
       "1           1  test  This is an example of why the majority of acti...   neg   \n",
       "2           2  test  First of all I hate those moronic rappers, who...   neg   \n",
       "3           3  test  Not even the Beatles could write songs everyon...   neg   \n",
       "4           4  test  Brass pictures (movies is not a fitting word f...   neg   \n",
       "\n",
       "          file  \n",
       "0      0_2.txt  \n",
       "1  10000_4.txt  \n",
       "2  10001_1.txt  \n",
       "3  10002_3.txt  \n",
       "4  10003_3.txt  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/imdb-review-dataset/imdb_master.csv', encoding=\"latin-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['test', 'train'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    75000\n",
       "test     25000\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_df = df[df.type=='train']\n",
    "test_df = df[df.type=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25001</th>\n",
       "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25002</th>\n",
       "      <td>This film lacked something I couldn't put my f...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25003</th>\n",
       "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25004</th>\n",
       "      <td>When I was little my parents took me along to ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "25000  Story of a man who has unnatural feelings for ...       neg\n",
       "25001  Airport '77 starts as a brand new luxury 747 p...       neg\n",
       "25002  This film lacked something I couldn't put my f...       neg\n",
       "25003  Sorry everyone,,, I know this is supposed to b...       neg\n",
       "25004  When I was little my parents took me along to ...       neg"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_df = tran_df.drop(['Unnamed: 0','type','file'],axis=1)\n",
    "tran_df.columns = [\"review\",\"sentiment\"]\n",
    "tran_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unsup    50000\n",
       "pos      12500\n",
       "neg      12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_df = tran_df[tran_df.sentiment != 'unsup']\n",
    "tran_df['sentiment'] = tran_df['sentiment'].map({'pos': 1, 'neg': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film lacked something I couldn't put my f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When I was little my parents took me along to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  Story of a man who has unnatural feelings for ...          0\n",
       "1  Airport '77 starts as a brand new luxury 747 p...          0\n",
       "2  This film lacked something I couldn't put my f...          0\n",
       "3  Sorry everyone,,, I know this is supposed to b...          0\n",
       "4  When I was little my parents took me along to ...          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tran_df = tran_df.reset_index().drop(['index'],axis=1)\n",
    "tran_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  Once again Mr. Costner has dragged out a movie...          0\n",
       "1  This is an example of why the majority of acti...          0\n",
       "2  First of all I hate those moronic rappers, who...          0\n",
       "3  Not even the Beatles could write songs everyon...          0\n",
       "4  Brass pictures (movies is not a fitting word f...          0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing data\n",
    "test_df = test_df.drop(['Unnamed: 0','type','file'],axis=1)\n",
    "test_df.columns = [\"review\",\"sentiment\"]\n",
    "test_df = test_df[test_df.sentiment != 'unsup']\n",
    "test_df['sentiment'] = test_df['sentiment'].map({'pos': 1, 'neg': 0})\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tran_df.review.values\n",
    "y_train = tran_df.sentiment.values\n",
    "\n",
    "X_test = test_df.review.values\n",
    "y_test = test_df.sentiment.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn Word Embedding\n",
    "The word embeddings of our dataset can be learned while training a neural network on the classification problem.\n",
    "\n",
    "Before put it into a network, the text data is first encoded so that each word is represented by a unique integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "total_reviews = X_train + X_test\n",
    "tokenizer.fit_on_texts(total_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average length of review in training dataset 461.29888\n"
     ]
    }
   ],
   "source": [
    "text_len = [len(i.split()) for i in total_reviews]\n",
    "print(\" Average length of review in training dataset\", np.mean(text_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max length\n",
    "#max_len = 460 the acc will stuck at 50%, try to use a smaller one\n",
    "max_len = 260\n",
    "\n",
    "# Define vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Pad sequences\n",
    "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tokens = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_tokens, maxlen=max_len, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_tokens, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Embedding layer requires the specification of the vocabulary size (vocab_size), the size of the real-valued vector space EMBEDDING_DIM = 100, and the maximum length of input documents max_length ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model\n",
    "The model will use an Embedding layer as the first hidden layer. The Embedding layer is initialized with random weights and will learn an embedding for all of the words in the training dataset during training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense\n",
    "\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(GRU(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complie model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 260, 100)          12500400  \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 32)                12864     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 12,513,297\n",
      "Trainable params: 12,513,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/25\n",
      "25000/25000 - 176s - loss: 0.6835 - acc: 0.5316 - val_loss: 0.6697 - val_acc: 0.5469\n",
      "Epoch 2/25\n",
      "25000/25000 - 170s - loss: 0.6243 - acc: 0.5913 - val_loss: 0.6438 - val_acc: 0.5756\n",
      "Epoch 3/25\n",
      "25000/25000 - 170s - loss: 0.5615 - acc: 0.6642 - val_loss: 0.5511 - val_acc: 0.7331\n",
      "Epoch 4/25\n",
      "25000/25000 - 169s - loss: 0.4379 - acc: 0.8158 - val_loss: 0.4206 - val_acc: 0.8368\n",
      "Epoch 5/25\n",
      "25000/25000 - 170s - loss: 0.3813 - acc: 0.8574 - val_loss: 0.4317 - val_acc: 0.8339\n",
      "Epoch 6/25\n",
      "25000/25000 - 171s - loss: 0.3919 - acc: 0.8489 - val_loss: 0.4207 - val_acc: 0.8352\n",
      "Epoch 7/25\n",
      "25000/25000 - 171s - loss: 0.3314 - acc: 0.8837 - val_loss: 0.4235 - val_acc: 0.8365\n",
      "Epoch 8/25\n",
      "25000/25000 - 172s - loss: 0.2927 - acc: 0.8956 - val_loss: 0.4348 - val_acc: 0.8252\n",
      "Epoch 9/25\n",
      "25000/25000 - 170s - loss: 0.3099 - acc: 0.8800 - val_loss: 0.4573 - val_acc: 0.8057\n",
      "Epoch 10/25\n",
      "25000/25000 - 171s - loss: 0.2262 - acc: 0.9217 - val_loss: 0.4678 - val_acc: 0.8176\n",
      "Epoch 11/25\n",
      "25000/25000 - 170s - loss: 0.1793 - acc: 0.9417 - val_loss: 0.4567 - val_acc: 0.8287\n",
      "Epoch 12/25\n",
      "25000/25000 - 171s - loss: 0.1472 - acc: 0.9546 - val_loss: 0.4799 - val_acc: 0.8272\n",
      "Epoch 13/25\n",
      "25000/25000 - 171s - loss: 0.1239 - acc: 0.9633 - val_loss: 0.4822 - val_acc: 0.8284\n",
      "Epoch 14/25\n",
      "25000/25000 - 170s - loss: 0.1053 - acc: 0.9699 - val_loss: 0.5023 - val_acc: 0.8280\n",
      "Epoch 15/25\n",
      "25000/25000 - 171s - loss: 0.0884 - acc: 0.9755 - val_loss: 0.5388 - val_acc: 0.8245\n",
      "Epoch 16/25\n",
      "25000/25000 - 170s - loss: 0.0733 - acc: 0.9809 - val_loss: 0.5750 - val_acc: 0.8212\n",
      "Epoch 17/25\n",
      "25000/25000 - 171s - loss: 0.0616 - acc: 0.9840 - val_loss: 0.6021 - val_acc: 0.8216\n",
      "Epoch 18/25\n",
      "25000/25000 - 169s - loss: 0.0533 - acc: 0.9867 - val_loss: 0.6221 - val_acc: 0.8218\n",
      "Epoch 19/25\n",
      "25000/25000 - 171s - loss: 0.0455 - acc: 0.9889 - val_loss: 0.6503 - val_acc: 0.8183\n",
      "Epoch 20/25\n",
      "25000/25000 - 170s - loss: 0.0370 - acc: 0.9908 - val_loss: 0.6778 - val_acc: 0.8184\n",
      "Epoch 21/25\n",
      "25000/25000 - 170s - loss: 0.0307 - acc: 0.9932 - val_loss: 0.7501 - val_acc: 0.8143\n",
      "Epoch 22/25\n",
      "25000/25000 - 170s - loss: 0.0254 - acc: 0.9943 - val_loss: 0.7757 - val_acc: 0.8136\n",
      "Epoch 23/25\n",
      "25000/25000 - 170s - loss: 0.0231 - acc: 0.9948 - val_loss: 0.7958 - val_acc: 0.8123\n",
      "Epoch 24/25\n",
      "25000/25000 - 171s - loss: 0.0205 - acc: 0.9950 - val_loss: 0.8319 - val_acc: 0.8110\n",
      "Epoch 25/25\n",
      "25000/25000 - 170s - loss: 0.0223 - acc: 0.9942 - val_loss: 0.7792 - val_acc: 0.8171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0978d4a978>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix model\n",
    "model.fit(X_train_pad, y_train, batch_size=128, epochs=25, validation_data=(X_test_pad, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 73s 3ms/sample - loss: 0.7792 - acc: 0.8171\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test_pad, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
    "model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 260, 100)          12500400  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                17024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 12,517,457\n",
      "Trainable params: 12,517,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/25\n",
      "25000/25000 - 177s - loss: 0.6715 - accuracy: 0.5669 - val_loss: 0.5747 - val_accuracy: 0.7717\n",
      "Epoch 2/25\n",
      "25000/25000 - 173s - loss: 0.5461 - accuracy: 0.7570 - val_loss: 0.4958 - val_accuracy: 0.7907\n",
      "Epoch 3/25\n",
      "25000/25000 - 172s - loss: 0.5432 - accuracy: 0.7304 - val_loss: 0.5212 - val_accuracy: 0.7744\n",
      "Epoch 4/25\n",
      "25000/25000 - 173s - loss: 0.4572 - accuracy: 0.8143 - val_loss: 0.4757 - val_accuracy: 0.8014\n",
      "Epoch 5/25\n",
      "25000/25000 - 172s - loss: 0.4492 - accuracy: 0.8099 - val_loss: 0.5727 - val_accuracy: 0.7100\n",
      "Epoch 6/25\n",
      "25000/25000 - 174s - loss: 0.4308 - accuracy: 0.8252 - val_loss: 0.4895 - val_accuracy: 0.8041\n",
      "Epoch 7/25\n",
      "25000/25000 - 174s - loss: 0.3776 - accuracy: 0.8552 - val_loss: 0.4973 - val_accuracy: 0.8088\n",
      "Epoch 8/25\n",
      "25000/25000 - 173s - loss: 0.3587 - accuracy: 0.8662 - val_loss: 0.5067 - val_accuracy: 0.8051\n",
      "Epoch 9/25\n",
      "25000/25000 - 174s - loss: 0.3525 - accuracy: 0.8679 - val_loss: 0.5158 - val_accuracy: 0.8076\n",
      "Epoch 10/25\n",
      "25000/25000 - 175s - loss: 0.3457 - accuracy: 0.8703 - val_loss: 0.5224 - val_accuracy: 0.8049\n",
      "Epoch 11/25\n",
      "25000/25000 - 175s - loss: 0.3379 - accuracy: 0.8741 - val_loss: 0.5341 - val_accuracy: 0.7983\n",
      "Epoch 12/25\n",
      "25000/25000 - 172s - loss: 0.3371 - accuracy: 0.8738 - val_loss: 0.5350 - val_accuracy: 0.8035\n",
      "Epoch 13/25\n",
      "25000/25000 - 175s - loss: 0.3235 - accuracy: 0.8800 - val_loss: 0.5353 - val_accuracy: 0.8012\n",
      "Epoch 14/25\n",
      "25000/25000 - 174s - loss: 0.3352 - accuracy: 0.8732 - val_loss: 0.5918 - val_accuracy: 0.7940\n",
      "Epoch 15/25\n",
      "25000/25000 - 172s - loss: 0.3285 - accuracy: 0.8765 - val_loss: 0.5459 - val_accuracy: 0.8029\n",
      "Epoch 16/25\n",
      "25000/25000 - 173s - loss: 0.3303 - accuracy: 0.8699 - val_loss: 0.5308 - val_accuracy: 0.8046\n",
      "Epoch 17/25\n",
      "25000/25000 - 172s - loss: 0.3169 - accuracy: 0.8696 - val_loss: 0.5200 - val_accuracy: 0.7930\n",
      "Epoch 18/25\n",
      "25000/25000 - 173s - loss: 0.2754 - accuracy: 0.8872 - val_loss: 0.4926 - val_accuracy: 0.8278\n",
      "Epoch 19/25\n",
      "25000/25000 - 172s - loss: 0.2468 - accuracy: 0.9018 - val_loss: 0.5665 - val_accuracy: 0.7904\n",
      "Epoch 20/25\n",
      "25000/25000 - 173s - loss: 0.2424 - accuracy: 0.9136 - val_loss: 0.4709 - val_accuracy: 0.8340\n",
      "Epoch 21/25\n",
      "25000/25000 - 173s - loss: 0.2138 - accuracy: 0.9277 - val_loss: 0.4353 - val_accuracy: 0.8410\n",
      "Epoch 22/25\n",
      "25000/25000 - 173s - loss: 0.1773 - accuracy: 0.9441 - val_loss: 0.4179 - val_accuracy: 0.8530\n",
      "Epoch 23/25\n",
      "25000/25000 - 173s - loss: 0.1207 - accuracy: 0.9639 - val_loss: 0.4450 - val_accuracy: 0.8536\n",
      "Epoch 24/25\n",
      "25000/25000 - 172s - loss: 0.0876 - accuracy: 0.9746 - val_loss: 0.5116 - val_accuracy: 0.8494\n",
      "Epoch 25/25\n",
      "25000/25000 - 173s - loss: 0.0689 - accuracy: 0.9812 - val_loss: 0.5097 - val_accuracy: 0.8522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f08e44fb5c0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad, y_train, batch_size=128, epochs=25, validation_data=(X_test_pad, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 72s 3ms/sample - loss: 0.5097 - accuracy: 0.8522\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test_pad, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
